{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "os.chdir(\"../\")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from src.data import DataProcessing, HF_Dataset\n",
    "from src.utils import get_split_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset monash_tsf (/home/onyxia/.cache/huggingface/datasets/monash_tsf/traffic_hourly/1.0.0/82998723d55d6edbc664cfaebe371004d849846ee5f61b57f1f974000d44c050)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b829388a1be4897887df7cc0d5b646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"monash_tsf\", \"traffic_hourly\")\n",
    "freq = \"1H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = DataProcessing(dataset)\n",
    "# mtrain, mtest = data_pipeline.multi_variate_format(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 26, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_split_limit(10*[1., 2., 3.], np.array([0.7, 0.2, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = HF_Dataset(\n",
    "    [datetime(2023, 4, 12, 12, 0, 0), datetime(2023, 4, 12, 13, 0, 0)], \n",
    "    [10*[1, 2, 3], 10*[4, 5, 6]],\n",
    "    np.array([0.7, 0.2, 0.1]),\n",
    "    [10*[0, 0, 0], 10*[0, 0, 0]],\n",
    "    [10*[None, None, None], 10*[None, None, None]]).getDatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 30 and the array at index 1 has size 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_pipeline \u001b[39m=\u001b[39m DataProcessing(ds)\n\u001b[0;32m----> 2\u001b[0m data_pipeline\u001b[39m.\u001b[39;49mmulti_variate_format(freq)\n",
      "File \u001b[0;32m~/work/ts_forecasting/src/data/processing.py:44\u001b[0m, in \u001b[0;36mDataProcessing.multi_variate_format\u001b[0;34m(self, freq)\u001b[0m\n\u001b[1;32m     34\u001b[0m train_grouper \u001b[39m=\u001b[39m MultivariateGrouper(\n\u001b[1;32m     35\u001b[0m                     max_target_dim\u001b[39m=\u001b[39mnum_of_variates\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m test_grouper \u001b[39m=\u001b[39m MultivariateGrouper(\n\u001b[1;32m     38\u001b[0m                     max_target_dim\u001b[39m=\u001b[39mnum_of_variates,\n\u001b[1;32m     39\u001b[0m                     num_test_dates\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\n\u001b[1;32m     40\u001b[0m                                     num_of_variates),\n\u001b[1;32m     41\u001b[0m                 )\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     train_grouper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset),\n\u001b[0;32m---> 44\u001b[0m     test_grouper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_dataset)\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/gluonts/dataset/multivariate_grouper.py:88\u001b[0m, in \u001b[0;36mMultivariateGrouper.__call__\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, dataset: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess(dataset)\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_group_all(dataset)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/gluonts/dataset/multivariate_grouper.py:126\u001b[0m, in \u001b[0;36mMultivariateGrouper._group_all\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    124\u001b[0m     grouped_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_train_data(dataset)\n\u001b[1;32m    125\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     grouped_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_test_data(dataset)\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m grouped_dataset\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/gluonts/dataset/multivariate_grouper.py:169\u001b[0m, in \u001b[0;36mMultivariateGrouper._prepare_test_data\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m dataset_at_test_date \u001b[39min\u001b[39;00m split_dataset:\n\u001b[1;32m    168\u001b[0m     grouped_data \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m--> 169\u001b[0m     grouped_data[FieldName\u001b[39m.\u001b[39mTARGET] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack(dataset_at_test_date)\n\u001b[1;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m FieldName\u001b[39m.\u001b[39mFEAT_DYNAMIC_REAL \u001b[39min\u001b[39;00m fields:\n\u001b[1;32m    172\u001b[0m         grouped_data[FieldName\u001b[39m.\u001b[39mFEAT_DYNAMIC_REAL] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(\n\u001b[1;32m    173\u001b[0m             [data[FieldName\u001b[39m.\u001b[39mFEAT_DYNAMIC_REAL] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataset],\n\u001b[1;32m    174\u001b[0m         )\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 30 and the array at index 1 has size 31"
     ]
    }
   ],
   "source": [
    "data_pipeline = DataProcessing(ds)\n",
    "data_pipeline.multi_variate_format(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import (\n",
    "    MultivariateGrouper\n",
    ")\n",
    "\n",
    "num_of_variates = len(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': Period('2023-04-12 12:00', 'H'),\n",
       " 'target': [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
       " 'feat_static_cat': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'feat_dynamic_real': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'item_id': 'T0'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(\n",
    "                            max_target_dim=num_of_variates\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 1.,\n",
       "        2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 1., 2., 3., 2.],\n",
       "       [5., 4., 5., 6., 4., 5., 6., 4., 5., 6., 4., 5., 6., 4., 5., 6.,\n",
       "        4., 5., 6., 4., 5., 6., 4., 5., 6., 4., 5., 6., 4., 5., 6.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grouper(ds[\"test\"])[0][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
